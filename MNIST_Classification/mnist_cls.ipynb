{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datapreprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = fetch_openml('mnist_784', parser = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0            0  ...         0         0         0         0         0   \n",
       "1            0  ...         0         0         0         0         0   \n",
       "2            0  ...         0         0         0         0         0   \n",
       "3            0  ...         0         0         0         0         0   \n",
       "4            0  ...         0         0         0         0         0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995        0  ...         0         0         0         0         0   \n",
       "69996        0  ...         0         0         0         0         0   \n",
       "69997        0  ...         0         0         0         0         0   \n",
       "69998        0  ...         0         0         0         0         0   \n",
       "69999        0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995         0         0         0         0         0  \n",
       "69996         0         0         0         0         0  \n",
       "69997         0         0         0         0         0  \n",
       "69998         0         0         0         0         0  \n",
       "69999         0         0         0         0         0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "X = torch.tensor(dataset.data.to_numpy(np.float32))\n",
    "y = torch.tensor(dataset.target.to_numpy(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples : 70000\n",
      "Number of training pixels : 784\n",
      "Number of training classes : 10\n"
     ]
    }
   ],
   "source": [
    "n_train = len(dataset.data)\n",
    "n_pixels = len(dataset.data.columns)\n",
    "n_classes = len(set(dataset.target))\n",
    "\n",
    "\n",
    "print(f'Number of training samples : {n_train}')\n",
    "print(f'Number of training pixels : {n_pixels}')\n",
    "print(f'Number of training classes : {n_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(dataset.data, dataset.target, test_size = 0.2 , random_state = 42, stratify = y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2 , random_state = 42 ,stratify = y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train X : (44800, 784)\n",
      "Number of train y : (44800,)\n",
      "\n",
      "Number of valid X : (14000, 784)\n",
      "Number of valid y : (14000,)\n",
      "\n",
      "Number of test X : (11200, 784)\n",
      "Number of test y : (11200,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train X : {X_train.shape}')\n",
    "print(f'Number of train y : {y_train.shape}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Number of valid X : {X_valid.shape}')\n",
    "print(f'Number of valid y : {y_valid.shape}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'Number of test X : {X_test.shape}')\n",
    "print(f'Number of test y : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, X , y , transform = None):\n",
    "        self.X = X.values.reshape((-1,28,28)).astype(np.float32)[:,:,:,None]\n",
    "        self.y = torch.from_numpy(y.to_numpy(dtype=np.uint64))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        print(self.X.shape)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms \n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "     [transforms.ToTensor(),\n",
    "     transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "\n",
    "val_test_transforms = transforms.Compose(\n",
    "     [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5,), std=(0.5,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_visualization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 241.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "\n",
    "random_sel = np.random.randint(n_train, size = 8)\n",
    "# torch.Tensor(X_train.iloc[random_sel, :].values)\n",
    "grid = make_grid(torch.Tensor((X_train.iloc[random_sel, :].values/255.)).reshape((-1,28,28)).unsqueeze(1) , nrow = 8)\n",
    "\n",
    "plt.figure(figsize=(16,2))\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.axis('off')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size , num_class):\n",
    "        \"\"\"\n",
    "        input_size = (1,28,28)\n",
    "        num_classes = 10\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_size[0], 32, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*64 , num_class)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = CNN((1,28,28), 10)\n",
    "print(model)\n",
    "opts = {\n",
    "    'lr' : 1e-3,\n",
    "    'epochs' : 20,\n",
    "    'batch_size' : 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), opts['lr'])\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44800, 28, 28, 1)\n",
      "(14000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MNISTDataset(X_train, y_train, transform = train_transforms)\n",
    "valid_dataset = MNISTDataset(X_valid, y_valid, transform = val_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = opts['batch_size'], shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_dataset, batch_size = opts['batch_size'], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 256/700 [00:09<00:16, 26.51it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i , (data, labels) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader) , total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)):\n\u001b[1;32m     10\u001b[0m     data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36mMNISTDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[idx]\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[idx]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[idx])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torchvision/transforms/functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/mnist/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:926\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    925\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(opts['epochs']):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for i , (data, labels) in tqdm(enumerate(train_loader) , total = len(train_loader)):\n",
    "        data.to(device)\n",
    "        labels.to(device)\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    for i , (data, labels) in enumerate(valid_loader):\n",
    "        data.to(device)\n",
    "        labels.to(device)\n",
    "        outputs = model(data)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss.append(loss.item())\n",
    "        test_accuracy.append((pred == labels).sum().item() / pred.size(0))\n",
    "    \n",
    "    print('epoch: {}, train loss: {}, test loss: {}, test accuracy: {}'.format(epoch, np.mean(train_loss), np.mean(test_loss), np.mean(test_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
